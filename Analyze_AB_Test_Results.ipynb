{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "## Table of Contents\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas, numby, random and matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read CSV file\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of rows & columns, 294478 rows and 5 cloumns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of unique users\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uses mean() to find the proportion of users converted\n",
    "df.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The number of times the `new_page` and `treatment` don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use query to find out the number of times the new_page and treatment don't line up\n",
    "treatment_old = df.query('group == \"treatment\" and landing_page == \"old_page\"').nunique()\n",
    "control_new = df.query('group == \"control\" and landing_page == \"new_page\"').nunique()\n",
    "treatment_old, control_new, treatment_old + control_new\n",
    "df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page'))== False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# check for any missing data in this dataset - no missing data since we had the same number of value for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat new dataset stored in new dataframe df2\n",
    "df2 = df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page'))]\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the correct rows is removed \n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique **user_id**s are in **df2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of unique users in df2\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any duplicated rows - there's 1 duplicated row\n",
    "sum(df2['user_id'].duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the information of the duplicated row\n",
    "ids = df2[\"user_id\"]\n",
    "df2[ids.isin(ids[ids.duplicated()])].sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haya3\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the duplicated row\n",
    "df2.drop([2893], inplace=True)\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check again to ensure the duplicated row was removed \n",
    "sum(df2['user_id'].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of an individual converting regardless of the page they receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses converted column to check for the probability of all users converted\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses group column to check of the probability of converted users in control group\n",
    "df2.query('group == \"control\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses group column to check of the probability of converted users in treatment group\n",
    "df2.query('group == \"treatment\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses landing_page column to check of the probability that an individual received the new page\n",
    "df2.query(\"landing_page == 'new_page'\").count()[0]/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider our results, we will find out below whether we think there is sufficient evidence to say that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall conversions rate:** 11.96%                                                                                               \n",
    "**Control group - old page conversions rate:** 12.04%                                                                               \n",
    "**Treatment group - new page conversions rate:** 11.88 %                                                                           \n",
    "                                                                                                                               \n",
    "Both groups received the pages equally, however the treatment group showed a decrease in conversions rate by 08% while the control group increased by 08%, even with this  small difference the results shows that the old page is more effective than the new page.                                                                                                                       \n",
    "So, there's no proof that the new page is better than the old based on the conversion rate only.                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, we could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do we run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "For now, consider we need to make the decision just based on all the data provided.  If we want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be? \n",
    "We can state our hypothesis in terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: The new page is worse or the same as the old page.                                                                     \n",
    "**$p_{new}$** - **$p_{old}$**  <= 0                                                                                                             \n",
    "**Alternative hypothesis**: The new page is better than the old page.                                                                                                                                                                      \n",
    "**$p_{new}$** - **$p_{old}$**  > 0                                                                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **convert rate** for $p_{new}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#under the null hypothesis the convertion rate 11.96%\n",
    "p_new = df2.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **convert rate** for $p_{old}$ under the null <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#under the null hypothesis the convertion rate 11.96%\n",
    "p_old = df2.converted.mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of individuals who converted to new page is 145310\n",
    "n_new = df2.query(\"landing_page == 'new_page'\")['converted'].count()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n_{old}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of individuals who converted to new page is 145274\n",
    "n_old = df2.query(\"landing_page == 'old_page'\")['converted'].count()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11992292340513386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses np.random.binomial to Simulate n_new transactions with a convert rate of p_new under the null hypothesis\n",
    "new_page_converted = np.random.binomial(1, p_new, n_new)\n",
    "new_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1202210994396795"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses np.random.binomial to Simulate n_old transactions with a convert rate of p_old under the null hypothesis\n",
    "old_page_converted = np.random.binomial(1, p_old, n_old)\n",
    "old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $p_{new}$ - $p_{old}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in the observed simulation: -0.00029817603454564134\n"
     ]
    }
   ],
   "source": [
    "#find the difference in the observed simulation\n",
    "simulation_diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "print('The difference in the observed simulation: {}'.format(simulation_diff.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.119612645070694, 0.11960522331566995, -7.421755024051774e-06)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses np.random.binomial to Simulate 10,000  p_new - p_old values\n",
    "new_converted_simulation = np.random.binomial(n_new, p_new, 10000)/n_new\n",
    "old_converted_simulation = np.random.binomial(n_old, p_old, 10000)/n_old\n",
    "p_diffs = new_converted_simulation - old_converted_simulation\n",
    "p_diffs = np.array(p_diffs)\n",
    "old_converted_simulation.mean(), new_converted_simulation.mean(), p_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the **p_diffs**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the actual difference for each group\n",
    "control_convert_actual = df2.query('group == \"control\"')['converted'].mean()\n",
    "treatment_convert_actual = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "observed_diff = treatment_convert_actual - control_convert_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the confidence interval\n",
    "p_diffs = np.array(p_diffs)\n",
    "low, upper = np.percentile(p_diffs, 2.5), np.percentile(p_diffs, 97.5)\n",
    "low, upper\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(x=low, color='g', linewidth=2);\n",
    "plt.axvline(x=upper, color='g', linewidth=2);\n",
    "plt.axvline(observed_diff, color='r', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Central Limit Theorem, with a large enough sample size the sample mean follows a normal distribution as expected. \n",
    "Also, looking at the 97% Confidence Interval, most data points fall within this area suggesting that the null hypothesis value generated this statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual observed difference is: -0.0015782389853555567\n",
      "The proportion of p_diffs greater than observed (p-value): 0.9068\n"
     ]
    }
   ],
   "source": [
    "#find proportion of values greater than observed_diff since alternative hypothesis > null hypothesis\n",
    "print(\"The actual observed difference is: {}\".format(observed_diff))\n",
    "print(\"The proportion of p_diffs greater than observed (p-value): {}\".format((p_diffs > observed_diff).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the alternative hypothesis is **p_new > p_old**, the probability that our observed statistic comes from this distribution is the shading from the observed statistic the red line to the right, and this is more than half of the distribution suggesting that our observed statistic does fall within right tail and supporting the null hypothesis that is: the old page converts better or equal than the new page.\n",
    "                                                                                                                              \n",
    "                                 \n",
    "The p-value is the probability of observing our statistic or more extreme values in favor of the alternative hypothesis which is greater in this case, if the null hypothesis is true.                                                                       \n",
    "While small p-value  means it is unlikely the we will observe our statistic from the null hypothesis, and more likely it came from the alternative hypothesis.                                                                                                                                                                                                                               \n",
    "                                                                                                                               \n",
    "**P-value**                                                                                                                     \n",
    "**Type I error:** Deciding the new page is better, but really the old page is better.                                           \n",
    "**Type II error:** Deciding the old page is better, but really the new page is better.                                         \n",
    "**Type I error threshold is :** 0.05                                                                                           \n",
    "**If p-value <= 0.05:** reject the null hypothesis.                                                                            \n",
    "**If p-value > 0.05 :** fail to reject the null hypothesis.                                                                    \n",
    "Since the p-value is **0.9** greater than the type I error threshold **0.05**, then trere's no reasonable evidence that the new page is better than the old page, so we fail to reject the null hypothesis.                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df2.query(\"landing_page == 'old_page' and converted == 1\").shape[0]\n",
    "convert_new = df2.query(\"landing_page == 'new_page' and converted == 1\").shape[0]\n",
    "n_old = df2.query(\"landing_page == 'old_page'\").shape[0]\n",
    "n_new = df2.query(\"landing_page == 'old_page'\").shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `stats.proportions_ztest` to compute your test statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.421755024051774e-06, 0.0011971003426360996, 1.4330492303394668e-06)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the p_diffs mean(), std() and var() \n",
    "p_diffs.mean(), p_diffs.std(), p_diffs.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2863207858559254, 0.9008344344112337)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the z_score \n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new], value=None, alternative='smaller', prop_var=False)\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default parameter for proportions_ztest assumes:                                                                           \n",
    "**Null hypothesis:** p_new - p_old = 0                                                                                         \n",
    "(no difference between two proportions)                                                                                         \n",
    "**Alternative hypothesis :** p_new - p_old != 0                                                                                 \n",
    " (a statistical difference between two proportions)                                                                             \n",
    "                                                                                                                               \n",
    "**P-value** is a probability that we have falsely rejected the null hypothesis, while **Z-score** measures standard deviation. \n",
    "                                                                                                                               \n",
    "This is another test of statistical significance that helps on decide whether or not to reject the null hypothesis.             \n",
    "In this case, since the standard deviation here is small but the p-value is large, that doesn't make a difference.             \n",
    "The large p-value suggests that : converstions of the old page are statistically better than the new page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "In this final part, we will see that the result we acheived in the previous A/B test can also be acheived by performing regression.<br><br>\n",
    "\n",
    "Since each row is either a conversion or no conversion, what type of regression should we be performing in this case?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression Types/ Models**                                                                                                   \n",
    "**Simple Linear:**                                                                                                              compare 2 quantitative variables - use one explanatory variable (x) to predict a response variable (y).                         \n",
    "**Multiple Linear :**                                                                                                     compare multiple explanatory variables (X) to predict a response variable (y), predicted response any value between negative and positive infinity.                                                                                                         \n",
    "**Logistic:**                                                                                                              predict categorical data with only 2 outcomes (predicts a probability between 0 and 1)                                         \n",
    "Logistic Regression should be used since we want to predict one of two  possible outcomes: whether a user will convert or not depending on the page (old or new)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to use **statsmodels** to fit the regression model to see if there is a significant difference in conversion based on which page a customer receives.  However, we first need to create a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-008024aeb792>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['intercept'] = 1\n",
      "C:\\Users\\haya3\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>control</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  new_page  old_page  control  ab_page  \n",
       "0          1         0         1        1        0  \n",
       "1          1         0         1        1        0  \n",
       "2          1         1         0        0        1  \n",
       "3          1         1         0        0        1  \n",
       "4          1         0         1        1        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column called intercept and new column for get_dummies() of pages\n",
    "df2['intercept'] = 1\n",
    "df2[['new_page', 'old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2[['control', 'ab_page']] = pd.get_dummies(df2['group'])\n",
    "#view head to ensure the new columns applied \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haya3\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  old_page  ab_page  \n",
       "0          1         1        0  \n",
       "1          1         1        0  \n",
       "2          1         0        1  \n",
       "3          1         0        1  \n",
       "4          1         1        0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use drop() to remove any unnecessary columns\n",
    "df2.drop(['new_page', 'control' ], axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to import regression model.  Instantiate the model, and fit the model using the two columns we created to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 20 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:04:52</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sun, 20 Jun 2021   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        09:04:52   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use logistic model\n",
    "logit_reg = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "results = logit_reg.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.015113064615719"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take the exponentiate the coefficients\n",
    "1/np.exp(-0.0150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new page is 1.015 times less likely to convert a users.                                                                     \n",
    "We used dummy variables to add categorical data to the matrix, when using dummies, we must remove one of the categories(since it is inferred by the remaining category - categories), and the intercept becomes the baseline removed category.               \n",
    "Since we removed 'control' and kept 'ab_page', that means  it becomes our baseline:                                             \n",
    "intercept = control group = old page.                                                                                           \n",
    "baseline : conversions are -1.9888.                                                                                             \n",
    "p-value for old_page: 0                                                                                                         \n",
    "statistically significant it's useful in predicting a response.                                                                 \n",
    "The slope: less conversions than old page, negative slope.                                                                     \n",
    "ab_page = treatment group = new page: -0.015 from intercept.                                                                   \n",
    "p-value for ab_page : 0.190                                                                                                     \n",
    "not statistically significant it's not useful in predicting a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression, the p-value is for testing if a parameter for intercept or slope equal zero **(Null hypothesis)** or does not equal zero **(alternative hypothesis)**.                                                                                                 \n",
    "                                                                                                                               \n",
    "**Null parameter  = 0**                                                                                                         \n",
    "**Alternative parameter  != 0**                                                                                                 \n",
    "Smaller p-values (< 0.05) suggest that specific variable is statistically significant in relating to the response variable, the slope associated with (x) in relating to (y) is non-zero.                                                                       \n",
    "p-value for old page (x): 0.0                                                                                                   \n",
    "Statistically significant in relating to the response variable, the slope associated with (x) in relating to (y) is non-zero.   \n",
    "p-value for new ab_page (x): 0.190                                                                                               \n",
    "Not statistically significant in relating to the response variable, the slope associated with (x) in relating to (y) is zero.   \n",
    "These p-values differ from previous p-value, because in the A/B test our null hypothesis consist that the old page is better than or equal to the new page (one-tailed).                                                                                             \n",
    "However, regression is a two-tailed test, therefore p-values have a different meaning regarding to slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**one of the disadvantages of adding additional terms into a regression model is:** collinearity.                                   \n",
    "We want to have a linear relationship between our predictor (X)with our response (y) variable, but when we add more predictors they might end up correlating with each other.                                                                                 \n",
    "                                                                                                                               \n",
    "Also, when (X) variables don't have a linear relationship, we could consider higher order terms, such as : interactions, quadratics, and cubics.                                                                                                         \n",
    "like: if the slopes of the  x variables are not parallel, this indicates that an interaction between those variables is present.                                                                                                                       \n",
    "In this case, we can create a new column that multiplies these two values and review this additional interaction with the predictor (y) variable.                                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. We will need to read in the **countries.csv** dataset and merge together our datasets on the approporiate rows.  \n",
    "\n",
    "Does it appear that country had an impact on conversion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load countries CSV file\n",
    "countries_df = pd.read_csv('./countries.csv')\n",
    "df_new = countries_df.set_index('user_id').join(df2.set_index('user_id'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of unique countries in this dstaset\n",
    "df_new['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  old_page  ab_page  CA  UK  US  \n",
       "user_id                                                       \n",
       "834778           0          1         1        0   0   1   0  \n",
       "928468           0          1         0        1   0   0   1  \n",
       "822059           1          1         0        1   0   1   0  \n",
       "711597           0          1         1        0   0   1   0  \n",
       "710616           0          1         0        1   0   1   0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the necessary dummy variables\n",
    "df_new[['CA', 'UK', 'US']] = pd.get_dummies(df_new['country'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 20 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:05:04</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9967</td> <td>    0.007</td> <td> -292.314</td> <td> 0.000</td> <td>   -2.010</td> <td>   -1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.746</td> <td> 0.456</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 20 Jun 2021   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        09:05:04   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9967      0.007   -292.314      0.000      -2.010      -1.983\n",
       "CA            -0.0408      0.027     -1.518      0.129      -0.093       0.012\n",
       "UK             0.0099      0.013      0.746      0.456      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use logistic model# drop US \n",
    "logit_reg = sm.Logit(df_new['converted'], df_new[['intercept', 'CA', 'UK']])\n",
    "results = logit_reg.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0416437559600236, 1.0099491671175422)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take the exponentiate the coefficients\n",
    "1/np.exp(-0.0408), np.exp(0.0099)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to **US** overall conversions:                                                                                         \n",
    "**CA** is 1.0416 times less likely to convert.                                                                                  \n",
    "**UK** is 1.0099 times more likely to convert.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>UK_new_page</th>\n",
       "      <th>US_new_page</th>\n",
       "      <th>CA_new_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  old_page  ab_page  CA  UK  US  UK_new_page  \\\n",
       "user_id                                                                     \n",
       "834778           0          1         1        0   0   1   0            0   \n",
       "928468           0          1         0        1   0   0   1            0   \n",
       "822059           1          1         0        1   0   1   0            1   \n",
       "711597           0          1         1        0   0   1   0            0   \n",
       "710616           0          1         0        1   0   1   0            1   \n",
       "\n",
       "         US_new_page  CA_new_page  \n",
       "user_id                            \n",
       "834778             0            0  \n",
       "928468             1            0  \n",
       "822059             0            0  \n",
       "711597             0            0  \n",
       "710616             0            0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fit Your Linear Model And Obtain the Results\n",
    "df_new['UK_new_page'] = df_new['UK']*df_new['ab_page']\n",
    "df_new['US_new_page'] = df_new['US']*df_new['ab_page']\n",
    "df_new['CA_new_page'] = df_new['CA']*df_new['ab_page']\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290579</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 20 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>2.417e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:44:18</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.2729</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>   -1.9967</td> <td>    0.007</td> <td> -292.314</td> <td> 0.000</td> <td>   -2.010</td> <td>   -1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>          <td>   -0.0073</td> <td>    0.037</td> <td>   -0.196</td> <td> 0.844</td> <td>   -0.080</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>          <td>    0.0045</td> <td>    0.018</td> <td>    0.257</td> <td> 0.797</td> <td>   -0.030</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_new_page</th> <td>   -0.0674</td> <td>    0.052</td> <td>   -1.297</td> <td> 0.195</td> <td>   -0.169</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_new_page</th> <td>    0.0108</td> <td>    0.023</td> <td>    0.475</td> <td> 0.635</td> <td>   -0.034</td> <td>    0.056</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290579\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 20 Jun 2021   Pseudo R-squ.:               2.417e-05\n",
       "Time:                        09:44:18   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.2729\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "intercept      -1.9967      0.007   -292.314      0.000      -2.010      -1.983\n",
       "CA             -0.0073      0.037     -0.196      0.844      -0.080       0.065\n",
       "UK              0.0045      0.018      0.257      0.797      -0.030       0.039\n",
       "CA_new_page    -0.0674      0.052     -1.297      0.195      -0.169       0.034\n",
       "UK_new_page     0.0108      0.023      0.475      0.635      -0.034       0.056\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use logistic model\n",
    "logit_reg = sm.Logit(df_new['converted'], df_new[['intercept','CA','UK','CA_new_page', 'UK_new_page']])\n",
    "results = logit_reg.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0073267099546657, 1.0045101402046013)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take the exponentiate the coefficients\n",
    "1/np.exp(-0.0073), np.exp(0.0045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0697232819209153, 1.010858530520097)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take the exponentiate the coefficients\n",
    "1/np.exp(-0.0674), np.exp(0.0108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "For the treatment group those that received the new page and compared to **US** conversions:                                       \n",
    "**CA** is 1.073 times less likely to convert to new page.                                                                                       \n",
    "**UK** is 1.011 times more likely to convert to new page.                                                                                       \n",
    "compared to **US, CA** the overall new page conversions is lower, and to **UK** overall new page conversions is higher, perhaps the **UK** has drawn to change while **CA** hasn't, but these observed differences are quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "                                                                                                                               \n",
    "     \n",
    "- It seems the old page has a higher convertion rate than the new page, In other words, the old page is more effactive than the new page, since :                                                                                                           \n",
    "**Overall conversions:** 11.96%                                                                                                     \n",
    "**Control (old page) conversions:** 12.04% (.08% increase)                                                                         \n",
    "**Treatment (new page) conversions:** 11.88% (.08% decrease)                                                                       \n",
    "known that each group received the the pages equally, however the treatment group showed a decrease in conversions rate by **08%** while the control group increased by **08%**.                                                                                                                                                                                                          \n",
    "- According to the AB test results that the new page is less or equal to the old page **(Null hypothesis)** which is true after get the test  results, while the **(alternative hypothesis)** is the new page is better the old page which is what we fail to prove, since there's not suffient evidence support this hypothesis.                                                                                                                                                                                                                                                                                                                   \n",
    "- The country has effact on the convertion rate between these country, while the new page convertion rate in **CA** is low, the **UK** new page convertion rate is high.                                                                                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
